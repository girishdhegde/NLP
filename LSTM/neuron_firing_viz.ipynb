{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Refs:\n",
    "    http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "    https://www.youtube.com/watch?v=1ZbLA7ofasY\n",
    "    https://towardsdatascience.com/visualising-lstm-activations-in-keras-b50206da96ff\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import HTML as html_print\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lstm import WordLSTM, LSTM, LSTMCell\n",
    "from data import WordTokenizer\n",
    "\n",
    "\n",
    "__author__ = '__Girish_Hegde__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_firing_hook(module, input, output):\n",
    "    \"\"\" Forward hook\n",
    "\n",
    "    Refs:\n",
    "        https://www.youtube.com/watch?v=1ZbLA7ofasY\n",
    "    \"\"\"\n",
    "    h_t, c_t = output\n",
    "    acts = h_t.detach()\n",
    "    module.net.activations = acts\n",
    "    # acts =  F.softmax(h_t.detach(), dim=-1)\n",
    "    # module.activations = acts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_hook(net, layers=[0, ], type=LSTMCell):\n",
    "    layers = set(layers)\n",
    "    net.activations = None\n",
    "    i = 0\n",
    "    for name, module in net.named_modules():\n",
    "        if isinstance(module, type):\n",
    "            if i in layers:\n",
    "                module.net = net\n",
    "                module.firing_hook = module.register_forward_hook(neuron_firing_hook)\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hexcolor(rgb):\n",
    "    r, g, b = rgb\n",
    "    if isinstance(r, float):\n",
    "        r, g, b = [int(v) for v in [r*255, g*255, b*255]]\n",
    "    clr = [hex(v).replace('0x', '').zfill(2) for v in (r, g, b)]\n",
    "    clr = '#' + ''.join(clr)\n",
    "    return clr\n",
    "\n",
    "\n",
    "# get html element\n",
    "def cstr(s, color='black'):\n",
    "\t\"\"\"\n",
    "\tRefs:\n",
    "\t\thttps://towardsdatascience.com/visualising-lstm-activations-in-keras-b50206da96ff\n",
    "\t\"\"\"\n",
    "\tif s == ' ':\n",
    "\t\treturn \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
    "\telse:\n",
    "\t\treturn \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
    "\n",
    "\n",
    "# print html\n",
    "def print_color(t):\n",
    "\t\"\"\"\n",
    "\tRefs:\n",
    "\t\thttps://towardsdatascience.com/visualising-lstm-activations-in-keras-b50206da96ff\n",
    "\t\"\"\"\n",
    "\tdisplay(html_print(''.join([cstr(ti, color=ci) for ti, ci in t])))\n",
    "\n",
    "\n",
    "# get appropriate color for value\n",
    "def get_clr(value):\n",
    "\t\"\"\"\n",
    "\tRefs:\n",
    "\t\thttps://towardsdatascience.com/visualising-lstm-activations-in-keras-b50206da96ff\n",
    "\t\"\"\"\n",
    "\tr, b = value, 1 - value\n",
    "\tclr = get_hexcolor((r, 0, b))\n",
    "\treturn clr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize(tokens, activations, neuron):\n",
    "\t\"\"\"\n",
    "\tRefs:\n",
    "\t\thttps://towardsdatascience.com/visualising-lstm-activations-in-keras-b50206da96ff\n",
    "\t\"\"\"\n",
    "\ttext_colours = []\n",
    "\tfor i, (tk, act) in enumerate(zip(tokens, activations)):\n",
    "\t\tvalue = act[neuron].item()\n",
    "\t\ttext = (tk, get_clr(value))\n",
    "\t\ttext_colours.append(text)\n",
    "\tprint_color(text_colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT = Path('./data/runs/best.pt')\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "TEXT = './data/datasets/corpus.txt'\n",
    "LAYER = 2\n",
    "N_WORDS = 10000\n",
    "\n",
    "ckpt = torch.load(CKPT, map_location=DEVICE)\n",
    "net = WordLSTM(ckpt['VOCAB_SIZE'], ckpt['EMBEDDING_DIM'], ckpt['HIDDEN_SIZE'], ckpt['NUM_LAYERS'])\n",
    "net.load_state_dict(ckpt['state_dict'])\n",
    "net = net.to(DEVICE)\n",
    "net.eval()\n",
    "init_states = net.init_hidden(1, DEVICE)\n",
    "\n",
    "int2token = ckpt['int2token']\n",
    "token2int = {tk: i for i, tk in int2token.items()}\n",
    "firing = []\n",
    "text = WordTokenizer.read(TEXT, encoding='utf-8')\n",
    "_, words, _ = WordTokenizer.tokenize(text, lowercase=True)\n",
    "words = [w for w in words if w in token2int]\n",
    "\n",
    "attach_hook(net, layers=[LAYER, ], type=LSTMCell)\n",
    "print('Color Palette')\n",
    "print_color([[' ', get_clr(v.item())] for v in torch.arange(255)/255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing = []\n",
    "init_states = net.init_hidden(1, DEVICE)\n",
    "for i, token in enumerate(words[:N_WORDS]):\n",
    "    enc = torch.tensor([[token2int[token]]], dtype=torch.int64, device=DEVICE)\n",
    "    pred, init_states = net(enc, init_states)\n",
    "    act = net.activations.clone()[0]\n",
    "    act = (act - act.min())/(act.max() - act.min())\n",
    "    firing.append(act)\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std = torch.std(torch.stack(firing), dim=0)\n",
    "# vs, idx = std.sort()\n",
    "visualize(words, firing, neuron=247)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0de187c9fa8dfa3c3f76f6436a7cfb7ae0dd2395cce8037080e53585a844224c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
