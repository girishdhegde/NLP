iteration: 500/100000, 	val loss: 4.089830033779144, 	train loss: 6.918695865790047, 	best loss: 4.089830033779144
iteration: 1000/100000, 	val loss: 3.280423254966736, 	train loss: 3.5900287010272334, 	best loss: 3.280423254966736
iteration: 1500/100000, 	val loss: 2.6718353259563448, 	train loss: 2.877771667718888, 	best loss: 2.6718353259563448
iteration: 2000/100000, 	val loss: 2.3938325452804565, 	train loss: 2.552999663352964, 	best loss: 2.3938325452804565
iteration: 2500/100000, 	val loss: 2.0352741050720216, 	train loss: 2.2648318414290767, 	best loss: 2.0352741050720216
iteration: 3000/100000, 	val loss: 2.048248983621597, 	train loss: 2.0417897737622246, 	best loss: 2.0352741050720216
iteration: 3500/100000, 	val loss: 1.8938921546936036, 	train loss: 1.8891101206541072, 	best loss: 1.8938921546936036
iteration: 4000/100000, 	val loss: 1.918795450925827, 	train loss: 1.7863542487919322, 	best loss: 1.8938921546936036
iteration: 4500/100000, 	val loss: 1.6973265540599822, 	train loss: 1.6710432790915164, 	best loss: 1.6973265540599822
iteration: 5000/100000, 	val loss: 1.6470936489105226, 	train loss: 1.616228737036387, 	best loss: 1.6470936489105226
iteration: 5500/100000, 	val loss: 1.6831178188323974, 	train loss: 1.5732844568689663, 	best loss: 1.6470936489105226
iteration: 6000/100000, 	val loss: 1.6928086221218108, 	train loss: 1.5202758523424467, 	best loss: 1.6470936489105226
iteration: 6500/100000, 	val loss: 1.6233925944566727, 	train loss: 1.4816998312870653, 	best loss: 1.6233925944566727
iteration: 7000/100000, 	val loss: 1.6061336398124695, 	train loss: 1.464466674089432, 	best loss: 1.6061336398124695
iteration: 7500/100000, 	val loss: 1.5350176727771758, 	train loss: 1.4481934317350382, 	best loss: 1.5350176727771758
iteration: 8000/100000, 	val loss: 1.4793921756744384, 	train loss: 1.4193383572995681, 	best loss: 1.4793921756744384
iteration: 8500/100000, 	val loss: 1.534958784878254, 	train loss: 1.4103211664060737, 	best loss: 1.4793921756744384
iteration: 9000/100000, 	val loss: 1.4208958238363265, 	train loss: 1.3702253137032183, 	best loss: 1.4208958238363265
iteration: 9500/100000, 	val loss: 1.464564925134182, 	train loss: 1.3552990775605043, 	best loss: 1.4208958238363265
iteration: 10000/100000, 	val loss: 1.4009742099046707, 	train loss: 1.347418976336718, 	best loss: 1.4009742099046707
iteration: 10500/100000, 	val loss: 1.4195182943344116, 	train loss: 1.3371127814253163, 	best loss: 1.4009742099046707
iteration: 11000/100000, 	val loss: 1.3936241751909255, 	train loss: 1.337015725940466, 	best loss: 1.3936241751909255
iteration: 11500/100000, 	val loss: 1.548442097902298, 	train loss: 1.3241096759835878, 	best loss: 1.3936241751909255
iteration: 12000/100000, 	val loss: 1.4939119273424148, 	train loss: 1.3183908402721087, 	best loss: 1.3936241751909255
iteration: 12500/100000, 	val loss: 1.3644957619905471, 	train loss: 1.2953001627226668, 	best loss: 1.3644957619905471
iteration: 13000/100000, 	val loss: 1.4171024560928345, 	train loss: 1.280050670276087, 	best loss: 1.3644957619905471
iteration: 13500/100000, 	val loss: 1.4354195648431778, 	train loss: 1.2767092895259464, 	best loss: 1.3644957619905471
iteration: 14000/100000, 	val loss: 1.2915796089172362, 	train loss: 1.2718906777203078, 	best loss: 1.2915796089172362
iteration: 14500/100000, 	val loss: 1.4445478761196135, 	train loss: 1.256675512542326, 	best loss: 1.2915796089172362
iteration: 15000/100000, 	val loss: 1.3024150341749192, 	train loss: 1.2583591573039685, 	best loss: 1.2915796089172362
iteration: 15500/100000, 	val loss: 1.3477540737390519, 	train loss: 1.257372567400338, 	best loss: 1.2915796089172362
iteration: 16000/100000, 	val loss: 1.3416772699356079, 	train loss: 1.2499513498743364, 	best loss: 1.2915796089172362
iteration: 16500/100000, 	val loss: 1.3842260318994521, 	train loss: 1.2252214848349485, 	best loss: 1.2915796089172362
iteration: 17000/100000, 	val loss: 1.3794550800323486, 	train loss: 1.241463707605997, 	best loss: 1.2915796089172362
iteration: 17000/100000, 	val loss: 1.3458717489242553, 	train loss: 0.0, 	best loss: 1.2915796089172362
iteration: 17500/100000, 	val loss: 1.3114537835121154, 	train loss: 1.2232980525493615, 	best loss: 1.2915796089172362
iteration: 18000/100000, 	val loss: 1.32148152500391, 	train loss: 1.217288841913143, 	best loss: 1.2915796089172362
iteration: 18500/100000, 	val loss: 1.2901446831226349, 	train loss: 1.213628888954719, 	best loss: 1.2901446831226349
iteration: 19000/100000, 	val loss: 1.339525367617607, 	train loss: 1.2193119242091963, 	best loss: 1.2901446831226349
iteration: 19500/100000, 	val loss: 1.2249163001775742, 	train loss: 1.1949928958515326, 	best loss: 1.2249163001775742
iteration: 20000/100000, 	val loss: 1.3490980958938599, 	train loss: 1.1900694366743165, 	best loss: 1.2249163001775742
iteration: 20500/100000, 	val loss: 1.269113792181015, 	train loss: 1.2006924271881587, 	best loss: 1.2249163001775742
iteration: 21000/100000, 	val loss: 1.3597474002838135, 	train loss: 1.2195166602035363, 	best loss: 1.2249163001775742
iteration: 21500/100000, 	val loss: 1.3184279257059097, 	train loss: 1.190911727890373, 	best loss: 1.2249163001775742
iteration: 22000/100000, 	val loss: 1.3694195708632468, 	train loss: 1.1925105526000261, 	best loss: 1.2249163001775742
iteration: 22500/100000, 	val loss: 1.3880663257837296, 	train loss: 1.1933717748373749, 	best loss: 1.2249163001775742
iteration: 23000/100000, 	val loss: 1.2878182280063628, 	train loss: 1.179659631833434, 	best loss: 1.2249163001775742
iteration: 23500/100000, 	val loss: 1.3805353260040283, 	train loss: 1.1769953330134346, 	best loss: 1.2249163001775742
iteration: 24000/100000, 	val loss: 1.3711571544408798, 	train loss: 1.1756069891701135, 	best loss: 1.2249163001775742
iteration: 24500/100000, 	val loss: 1.3946023434400558, 	train loss: 1.1735275699297576, 	best loss: 1.2249163001775742
iteration: 25000/100000, 	val loss: 1.290449206829071, 	train loss: 1.161705070778727, 	best loss: 1.2249163001775742
iteration: 25500/100000, 	val loss: 1.3039899265766144, 	train loss: 1.172073033928872, 	best loss: 1.2249163001775742
iteration: 26000/100000, 	val loss: 1.380557708144188, 	train loss: 1.1486741805324945, 	best loss: 1.2249163001775742
iteration: 26500/100000, 	val loss: 1.315170666575432, 	train loss: 1.1367477943499893, 	best loss: 1.2249163001775742
iteration: 27000/100000, 	val loss: 1.3886244761943818, 	train loss: 1.1441319302022468, 	best loss: 1.2249163001775742
iteration: 27500/100000, 	val loss: 1.1982695204019547, 	train loss: 1.1371220681269965, 	best loss: 1.1982695204019547
iteration: 28000/100000, 	val loss: 1.365601001381874, 	train loss: 1.1499550315489369, 	best loss: 1.1982695204019547
iteration: 28500/100000, 	val loss: 1.4445954322814942, 	train loss: 1.1392493570894002, 	best loss: 1.1982695204019547
iteration: 29000/100000, 	val loss: 1.2755509531497955, 	train loss: 1.1418870980342228, 	best loss: 1.1982695204019547
iteration: 29500/100000, 	val loss: 1.3348872232437134, 	train loss: 1.1247561724881328, 	best loss: 1.1982695204019547
iteration: 30000/100000, 	val loss: 1.211977126598358, 	train loss: 1.1142316108942043, 	best loss: 1.1982695204019547
iteration: 30500/100000, 	val loss: 1.2572389650344848, 	train loss: 1.119224089463553, 	best loss: 1.1982695204019547
iteration: 31000/100000, 	val loss: 1.2715663707256317, 	train loss: 1.116776949991783, 	best loss: 1.1982695204019547
iteration: 31500/100000, 	val loss: 1.2820197141170502, 	train loss: 1.108684562106928, 	best loss: 1.1982695204019547
iteration: 31500/100000, 	val loss: 1.2747066396474838, 	train loss: 0.0, 	best loss: 1.1982695204019547
iteration: 32000/100000, 	val loss: 1.2346162563562393, 	train loss: 1.1055108419582242, 	best loss: 1.1982695204019547
iteration: 32500/100000, 	val loss: 1.2528606793284416, 	train loss: 1.1017204480121523, 	best loss: 1.1982695204019547
iteration: 33000/100000, 	val loss: 1.2227504497766495, 	train loss: 1.1014020521293078, 	best loss: 1.1982695204019547
iteration: 33500/100000, 	val loss: 1.2746649068593978, 	train loss: 1.107097077563406, 	best loss: 1.1982695204019547
iteration: 34000/100000, 	val loss: 1.1607954049110412, 	train loss: 1.0836307019591336, 	best loss: 1.1607954049110412
iteration: 34500/100000, 	val loss: 1.2887011605501175, 	train loss: 1.0820112176239483, 	best loss: 1.1607954049110412
iteration: 35000/100000, 	val loss: 1.2032311910390854, 	train loss: 1.0942697545190658, 	best loss: 1.1607954049110412
iteration: 35500/100000, 	val loss: 1.3029363799095153, 	train loss: 1.1138104345897835, 	best loss: 1.1607954049110412
iteration: 36000/100000, 	val loss: 1.2712843519449235, 	train loss: 1.0884191462347892, 	best loss: 1.1607954049110412
iteration: 36500/100000, 	val loss: 1.3201209852099418, 	train loss: 1.0905515628010032, 	best loss: 1.1607954049110412
iteration: 37000/100000, 	val loss: 1.328243956565857, 	train loss: 1.0935763685504591, 	best loss: 1.1607954049110412
iteration: 37500/100000, 	val loss: 1.2401724010705948, 	train loss: 1.0812735625853138, 	best loss: 1.1607954049110412
iteration: 38000/100000, 	val loss: 1.336267883181572, 	train loss: 1.0794310629343002, 	best loss: 1.1607954049110412
iteration: 38500/100000, 	val loss: 1.3286704137921332, 	train loss: 1.079741929069161, 	best loss: 1.1607954049110412
iteration: 39000/100000, 	val loss: 1.3489853304624557, 	train loss: 1.078686150570711, 	best loss: 1.1607954049110412
iteration: 39500/100000, 	val loss: 1.2461821508407593, 	train loss: 1.0684250943809748, 	best loss: 1.1607954049110412
iteration: 40000/100000, 	val loss: 1.2672118738293647, 	train loss: 1.080721519934634, 	best loss: 1.1607954049110412
iteration: 40500/100000, 	val loss: 1.335128876566887, 	train loss: 1.058883073190848, 	best loss: 1.1607954049110412
iteration: 41000/100000, 	val loss: 1.2758685860037804, 	train loss: 1.0481828437248857, 	best loss: 1.1607954049110412
iteration: 41500/100000, 	val loss: 1.3468160557746887, 	train loss: 1.056184745937586, 	best loss: 1.1607954049110412
iteration: 42000/100000, 	val loss: 1.1717552226781844, 	train loss: 1.0503155141373484, 	best loss: 1.1607954049110412
iteration: 42500/100000, 	val loss: 1.332769097685814, 	train loss: 1.0650262620896096, 	best loss: 1.1607954049110412
iteration: 43000/100000, 	val loss: 1.411885095834732, 	train loss: 1.054465201685825, 	best loss: 1.1607954049110412
iteration: 43500/100000, 	val loss: 1.2438640439510344, 	train loss: 1.0592664316395906, 	best loss: 1.1607954049110412
iteration: 44000/100000, 	val loss: 1.3011576625704766, 	train loss: 1.0439454502314334, 	best loss: 1.1607954049110412
iteration: 44500/100000, 	val loss: 1.1759366995096208, 	train loss: 1.033893946001927, 	best loss: 1.1607954049110412
iteration: 45000/100000, 	val loss: 1.2257961869239806, 	train loss: 1.0406838052334877, 	best loss: 1.1607954049110412
iteration: 45500/100000, 	val loss: 1.2468410098552705, 	train loss: 1.037756989533702, 	best loss: 1.1607954049110412
iteration: 46000/100000, 	val loss: 1.253206177353859, 	train loss: 1.0290574791630107, 	best loss: 1.1607954049110412
iteration: 46500/100000, 	val loss: 1.2800659292936325, 	train loss: 1.0540705550163987, 	best loss: 1.1607954049110412
iteration: 47000/100000, 	val loss: 1.2797444140911103, 	train loss: 1.0478608155474076, 	best loss: 1.1607954049110412
iteration: 47500/100000, 	val loss: 1.2265518361330032, 	train loss: 1.0527176785965755, 	best loss: 1.1607954049110412
iteration: 48000/100000, 	val loss: 1.187754299044609, 	train loss: 1.0301737540811302, 	best loss: 1.1607954049110412
iteration: 48500/100000, 	val loss: 1.3640114319324494, 	train loss: 1.0485009309649467, 	best loss: 1.1607954049110412
iteration: 49000/100000, 	val loss: 1.2893502324819566, 	train loss: 1.0407766189674539, 	best loss: 1.1607954049110412
iteration: 49500/100000, 	val loss: 1.2734064495563506, 	train loss: 1.0360225112785897, 	best loss: 1.1607954049110412
iteration: 50000/100000, 	val loss: 1.1773722302913665, 	train loss: 1.0468302132425216, 	best loss: 1.1607954049110412
iteration: 50500/100000, 	val loss: 1.2899012529850007, 	train loss: 1.0381688839793208, 	best loss: 1.1607954049110412
iteration: 51000/100000, 	val loss: 1.2677962824702262, 	train loss: 1.0462400359263024, 	best loss: 1.1607954049110412
iteration: 51500/100000, 	val loss: 1.1742719972133637, 	train loss: 1.0375849817047516, 	best loss: 1.1607954049110412
iteration: 52000/100000, 	val loss: 1.1954608979821204, 	train loss: 1.0298847188651552, 	best loss: 1.1607954049110412
iteration: 52500/100000, 	val loss: 1.2912024635076522, 	train loss: 1.022575453683734, 	best loss: 1.1607954049110412
iteration: 53000/100000, 	val loss: 1.2847913384437561, 	train loss: 1.0170240026166038, 	best loss: 1.1607954049110412
iteration: 53500/100000, 	val loss: 1.275184571146965, 	train loss: 1.0181474476357293, 	best loss: 1.1607954049110412
iteration: 54000/100000, 	val loss: 1.2850352193415164, 	train loss: 1.0221879732161758, 	best loss: 1.1607954049110412
iteration: 54500/100000, 	val loss: 1.3826250904798507, 	train loss: 1.0314549674540763, 	best loss: 1.1607954049110412
iteration: 55000/100000, 	val loss: 1.2182450953125954, 	train loss: 1.0138484588960806, 	best loss: 1.1607954049110412
iteration: 55500/100000, 	val loss: 1.208550821840763, 	train loss: 1.0039903180797893, 	best loss: 1.1607954049110412
iteration: 56000/100000, 	val loss: 1.210028229355812, 	train loss: 1.0156861713528635, 	best loss: 1.1607954049110412
iteration: 56500/100000, 	val loss: 1.1756041678786278, 	train loss: 1.0083650492876763, 	best loss: 1.1607954049110412
iteration: 57000/100000, 	val loss: 1.2132487058639527, 	train loss: 1.0137888825585448, 	best loss: 1.1607954049110412
iteration: 57500/100000, 	val loss: 1.1692395281791688, 	train loss: 1.0140941423525418, 	best loss: 1.1607954049110412
iteration: 58000/100000, 	val loss: 1.213049919307232, 	train loss: 1.0087177340040605, 	best loss: 1.1607954049110412
iteration: 58500/100000, 	val loss: 1.278070940375328, 	train loss: 1.0211413743346927, 	best loss: 1.1607954049110412
iteration: 59000/100000, 	val loss: 1.208499664068222, 	train loss: 0.9996076126595339, 	best loss: 1.1607954049110412
iteration: 59500/100000, 	val loss: 1.1490878194570542, 	train loss: 0.9987824815188848, 	best loss: 1.1490878194570542
iteration: 60000/100000, 	val loss: 1.419336102604866, 	train loss: 0.9965563837538163, 	best loss: 1.1490878194570542
iteration: 60500/100000, 	val loss: 1.2628356719017029, 	train loss: 1.00556313080589, 	best loss: 1.1490878194570542
iteration: 61000/100000, 	val loss: 1.1657992947101592, 	train loss: 0.9903317459188411, 	best loss: 1.1490878194570542
iteration: 61500/100000, 	val loss: 1.2992550879716873, 	train loss: 0.9836767770449317, 	best loss: 1.1490878194570542
iteration: 62000/100000, 	val loss: 1.2330583643913269, 	train loss: 0.9893821498987576, 	best loss: 1.1490878194570542
iteration: 62500/100000, 	val loss: 1.2586543530225753, 	train loss: 0.9902853015785419, 	best loss: 1.1490878194570542
iteration: 63000/100000, 	val loss: 1.2054265856742858, 	train loss: 0.9934894153922802, 	best loss: 1.1490878194570542
iteration: 63500/100000, 	val loss: 1.1704522135853768, 	train loss: 0.9824865528643132, 	best loss: 1.1490878194570542
iteration: 64000/100000, 	val loss: 1.2006694358587264, 	train loss: 0.9810488142917564, 	best loss: 1.1490878194570542
iteration: 64500/100000, 	val loss: 1.1755829378962517, 	train loss: 0.9750709872817003, 	best loss: 1.1490878194570542
iteration: 65000/100000, 	val loss: 1.2193546032905578, 	train loss: 0.971981026669343, 	best loss: 1.1490878194570542
iteration: 65500/100000, 	val loss: 1.146967471241951, 	train loss: 0.9763374650776392, 	best loss: 1.146967471241951
iteration: 66000/100000, 	val loss: 1.3264241176843643, 	train loss: 0.9740167151391518, 	best loss: 1.146967471241951
iteration: 66500/100000, 	val loss: 1.3033353805541992, 	train loss: 0.9666795975367236, 	best loss: 1.146967471241951
iteration: 67000/100000, 	val loss: 1.1421644327044487, 	train loss: 0.9667215367431451, 	best loss: 1.1421644327044487
iteration: 67500/100000, 	val loss: 1.2687790423631669, 	train loss: 0.9660905469730499, 	best loss: 1.1421644327044487
iteration: 68000/100000, 	val loss: 1.1957109543681144, 	train loss: 0.9706130932793013, 	best loss: 1.1421644327044487
iteration: 68500/100000, 	val loss: 1.2518026876449584, 	train loss: 0.963133114962528, 	best loss: 1.1421644327044487
iteration: 69000/100000, 	val loss: 1.3413673079013824, 	train loss: 0.969481922040383, 	best loss: 1.1421644327044487
iteration: 69500/100000, 	val loss: 1.2199644032120704, 	train loss: 0.9525025934129961, 	best loss: 1.1421644327044487
iteration: 70000/100000, 	val loss: 1.189431380778551, 	train loss: 0.9652144980728624, 	best loss: 1.1421644327044487
iteration: 70500/100000, 	val loss: 1.1588886153697968, 	train loss: 0.9585484120175244, 	best loss: 1.1421644327044487
iteration: 70500/100000, 	val loss: 1.2170596832036973, 	train loss: 0.0, 	best loss: 1.1421644327044487
iteration: 71000/100000, 	val loss: 1.1613997998833656, 	train loss: 0.9470211780716968, 	best loss: 1.1421644327044487
iteration: 71500/100000, 	val loss: 1.1910080471634865, 	train loss: 0.9387131498530502, 	best loss: 1.1421644327044487
iteration: 72000/100000, 	val loss: 1.1517503941059113, 	train loss: 0.9404513111760218, 	best loss: 1.1421644327044487
iteration: 72500/100000, 	val loss: 1.212098079621792, 	train loss: 0.9476910735666756, 	best loss: 1.1421644327044487
iteration: 73000/100000, 	val loss: 1.0965057814121246, 	train loss: 0.9253154439181096, 	best loss: 1.0965057814121246
iteration: 73500/100000, 	val loss: 1.228903893828392, 	train loss: 0.9237228711893163, 	best loss: 1.0965057814121246
iteration: 74000/100000, 	val loss: 1.1400414115190507, 	train loss: 0.9355740560839567, 	best loss: 1.0965057814121246
iteration: 74500/100000, 	val loss: 1.2390742221474647, 	train loss: 0.9564734370907149, 	best loss: 1.0965057814121246
iteration: 75000/100000, 	val loss: 1.223625940680504, 	train loss: 0.9331745348100856, 	best loss: 1.0965057814121246
iteration: 75500/100000, 	val loss: 1.2672945243120193, 	train loss: 0.9368513750756771, 	best loss: 1.0965057814121246
iteration: 76000/100000, 	val loss: 1.2690294921398162, 	train loss: 0.9368630379736426, 	best loss: 1.0965057814121246
iteration: 76500/100000, 	val loss: 1.1818314200639726, 	train loss: 0.9297631479203697, 	best loss: 1.0965057814121246
iteration: 77000/100000, 	val loss: 1.2904464414715766, 	train loss: 0.9270694135427477, 	best loss: 1.0965057814121246
iteration: 77000/100000, 	val loss: 1.2194333636760712, 	train loss: 0.0, 	best loss: 1.0965057814121246
iteration: 77000/100000, 	val loss: 1.2194333636760712, 	train loss: 0.0, 	best loss: 1.0965057814121246
iteration: 77000/100000, 	val loss: 1.2194333636760712, 	train loss: 0.0, 	best loss: 1.0965057814121246
iteration: 77500/100000, 	val loss: 1.1653427791595459, 	train loss: 0.9032076425589612, 	best loss: 1.0965057814121246
iteration: 78000/100000, 	val loss: 1.1995662975311279, 	train loss: 0.8939707457721237, 	best loss: 1.0965057814121246
iteration: 78000/100000, 	val loss: 1.2611267322301865, 	train loss: 0.0, 	best loss: 1.0965057814121246
iteration: 78500/100000, 	val loss: 1.3030370971560479, 	train loss: 0.9351479464719687, 	best loss: 1.0965057814121246
iteration: 79000/100000, 	val loss: 1.2885015547275542, 	train loss: 0.9313548538535825, 	best loss: 1.0965057814121246
iteration: 79500/100000, 	val loss: 1.2962922263145447, 	train loss: 0.9432920371045659, 	best loss: 1.0965057814121246
iteration: 80000/100000, 	val loss: 1.2486547598242759, 	train loss: 0.9243006624678777, 	best loss: 1.0965057814121246
iteration: 80500/100000, 	val loss: 1.2214175754785537, 	train loss: 0.9268885441472138, 	best loss: 1.0965057814121246
iteration: 81000/100000, 	val loss: 1.2905228686332704, 	train loss: 0.9351127307713039, 	best loss: 1.0965057814121246
iteration: 81500/100000, 	val loss: 1.1994343253970146, 	train loss: 0.9363595271805916, 	best loss: 1.0965057814121246
iteration: 82000/100000, 	val loss: 1.1909181416034698, 	train loss: 0.9316610817387697, 	best loss: 1.0965057814121246
iteration: 82500/100000, 	val loss: 1.2221389052271843, 	train loss: 0.928816121240457, 	best loss: 1.0965057814121246
iteration: 83000/100000, 	val loss: 1.2188065600395204, 	train loss: 0.9323365649655463, 	best loss: 1.0965057814121246
iteration: 83500/100000, 	val loss: 1.2635928410291672, 	train loss: 0.9310079737603669, 	best loss: 1.0965057814121246
iteration: 84000/100000, 	val loss: 1.2382647854089737, 	train loss: 0.9073124982813989, 	best loss: 1.0965057814121246
iteration: 84500/100000, 	val loss: 1.1843287187814713, 	train loss: 0.9239313766658301, 	best loss: 1.0965057814121246
iteration: 85000/100000, 	val loss: 1.240804343521595, 	train loss: 0.9137649966925376, 	best loss: 1.0965057814121246
iteration: 85500/100000, 	val loss: 1.3087044906616212, 	train loss: 0.9319844619929787, 	best loss: 1.0965057814121246
iteration: 86000/100000, 	val loss: 1.2013314428925514, 	train loss: 0.9138019843051833, 	best loss: 1.0965057814121246
iteration: 86500/100000, 	val loss: 1.2315594658255578, 	train loss: 0.9162228324959675, 	best loss: 1.0965057814121246
iteration: 87000/100000, 	val loss: 1.1872123962640762, 	train loss: 0.9189805946896472, 	best loss: 1.0965057814121246
iteration: 87500/100000, 	val loss: 1.3278015339374543, 	train loss: 0.9147921291614571, 	best loss: 1.0965057814121246
iteration: 87500/100000, 	val loss: 1.25017223238945, 	train loss: 0.0, 	best loss: 1.0965057814121246
iteration: 88000/100000, 	val loss: 1.059177499115467, 	train loss: 0.9116802312886975, 	best loss: 1.059177499115467
iteration: 88500/100000, 	val loss: 1.1879814690351487, 	train loss: 0.913176167560121, 	best loss: 1.059177499115467
iteration: 89000/100000, 	val loss: 1.098367326259613, 	train loss: 0.9096569172690316, 	best loss: 1.059177499115467
iteration: 89500/100000, 	val loss: 1.3090527334809303, 	train loss: 0.9102982283085578, 	best loss: 1.059177499115467
iteration: 90000/100000, 	val loss: 1.258079579770565, 	train loss: 0.9066232332885263, 	best loss: 1.059177499115467
iteration: 90500/100000, 	val loss: 1.1824988809227943, 	train loss: 0.9010395308683314, 	best loss: 1.059177499115467
iteration: 91000/100000, 	val loss: 1.1569095799326896, 	train loss: 0.9089178751483564, 	best loss: 1.059177499115467
iteration: 91500/100000, 	val loss: 1.2611874306201936, 	train loss: 0.9162167459328966, 	best loss: 1.059177499115467
iteration: 92000/100000, 	val loss: 1.2865877842903137, 	train loss: 0.9196869644224643, 	best loss: 1.059177499115467
iteration: 92500/100000, 	val loss: 1.111559010744095, 	train loss: 0.9178880822857217, 	best loss: 1.059177499115467
iteration: 93000/100000, 	val loss: 1.192494851052761, 	train loss: 0.8995068091352783, 	best loss: 1.059177499115467
iteration: 93500/100000, 	val loss: 1.2701834762096404, 	train loss: 0.9064539282172925, 	best loss: 1.059177499115467
iteration: 94000/100000, 	val loss: 1.1527279049158097, 	train loss: 0.906780884539088, 	best loss: 1.059177499115467
iteration: 94500/100000, 	val loss: 1.1244323351979255, 	train loss: 0.9005574769477043, 	best loss: 1.059177499115467
iteration: 95000/100000, 	val loss: 1.2615055513381959, 	train loss: 0.8978799996972084, 	best loss: 1.059177499115467
iteration: 95500/100000, 	val loss: 1.232821465432644, 	train loss: 0.9156813944503657, 	best loss: 1.059177499115467
iteration: 96000/100000, 	val loss: 1.2928507721424103, 	train loss: 0.896533412858844, 	best loss: 1.059177499115467
iteration: 96500/100000, 	val loss: 1.2509896546602248, 	train loss: 0.9070431415463489, 	best loss: 1.059177499115467
iteration: 97000/100000, 	val loss: 1.2417322221398353, 	train loss: 0.8966234679917505, 	best loss: 1.059177499115467
iteration: 97500/100000, 	val loss: 1.2437265092134475, 	train loss: 0.9082231144458055, 	best loss: 1.059177499115467
iteration: 98000/100000, 	val loss: 1.2190364080667495, 	train loss: 0.8889290857116389, 	best loss: 1.059177499115467
iteration: 98500/100000, 	val loss: 1.2063007515668869, 	train loss: 0.8988724411875005, 	best loss: 1.059177499115467
iteration: 99000/100000, 	val loss: 1.2254606875777245, 	train loss: 0.9112675478458415, 	best loss: 1.059177499115467
iteration: 99500/100000, 	val loss: 1.2903597220778464, 	train loss: 0.8936970405330257, 	best loss: 1.059177499115467
iteration: 99500/100000, 	val loss: 1.2467690211534501, 	train loss: 0.0, 	best loss: 1.059177499115467
iteration: 99500/100001, 	val loss: 1.2037315872311591, 	train loss: 0.0, 	best loss: 1.059177499115467
iteration: 100000/100001, 	val loss: 1.1822884979844093, 	train loss: 0.902833381734789, 	best loss: 1.059177499115467
iteration: 100000/100000, 	val loss: 1.209987336397171, 	train loss: 0.0, 	best loss: 1.059177499115467
iteration: 100000/100000, 	val loss: 1.2989357012510299, 	train loss: 0.0, 	best loss: 1.059177499115467
iteration: 100000/100000, 	val loss: 1.1690975248813629, 	train loss: 0.0, 	best loss: 1.059177499115467
